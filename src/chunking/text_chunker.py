from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.documents import Document
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
import os
import shutil
import pickle

import os
from dotenv import load_dotenv

load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")


class HybridSectionChunker:
    
    def __init__(self, chunk_size=1000, chunk_overlap=100):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        
        # 1. Section splitter - tÃ¡ch theo markdown headers
        self.headers_to_split_on = [
            ("#", "h1"),
            ("##", "h2"),
            # ("###", "h3"),
            # ("####", "h4")
        ]
        self.section_splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=self.headers_to_split_on,
            strip_headers=True
        )
        
        # 2. Recursive splitter - tÃ¡ch sections lá»›n
        self.recursive_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model=EMBEDDING_MODEL_NAME,
            api_key=GEMINI_API_KEY
        )
    
    def chunk_and_save_to_db(self, md_file_path, collection_name="knowledge_base", 
                             persist_directory="data/chroma_db", reset=False):
        
        print(f"\nğŸ”ª HYBRID SECTION CHUNKING")
        print(f"="*70)
        print(f"ğŸ“„ File: {md_file_path}")
        print(f"ğŸ“ Chunk size: {self.chunk_size}")
        print(f"ğŸ”— Chunk overlap: {self.chunk_overlap}")
        
        if reset and os.path.exists(persist_directory):
            print(f"ğŸ—‘ï¸  XÃ³a DB cÅ©...")
            shutil.rmtree(persist_directory)
        
        os.makedirs(persist_directory, exist_ok=True)
        
        # Load document
        with open(md_file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        # Step 1: TÃ¡ch theo headers
        print(f"\nğŸ“‘ BÆ°á»›c 1: TÃ¡ch theo markdown headers...")
        section_docs = self.section_splitter.split_text(text)
        print(f"â†’ {len(section_docs)} sections")
        
        # Step 2: Recursive split cho sections lá»›n
        print(f"ğŸ”¨ BÆ°á»›c 2: Recursive split cho sections lá»›n...")
        final_chunks = []
        
        for idx, section_doc in enumerate(section_docs):
            section_doc.metadata.update({
                "source": md_file_path,
                "section_id": idx,
                "document": os.path.basename(md_file_path).replace('.md', '')
            })
            
            # Náº¿u section quÃ¡ lá»›n, tÃ¡ch tiáº¿p
            if len(section_doc.page_content) > self.chunk_size:
                sub_chunks = self.recursive_splitter.split_documents([section_doc])
                
                # ThÃªm sub_chunk_id
                for sub_idx, sub_chunk in enumerate(sub_chunks):
                    sub_chunk.metadata.update({
                        "sub_chunk_id": sub_idx,
                        "total_sub_chunks": len(sub_chunks)
                    })
                final_chunks.extend(sub_chunks)
            else:
                final_chunks.append(section_doc)
        
        print(f"   â†’ {len(final_chunks)} chunks cuá»‘i cÃ¹ng")
        
        # Step 3: LÆ°u vÃ o Chroma (cho semantic search)
        print(f"\nğŸ’¾ BÆ°á»›c 3: LÆ°u vÃ o Chroma DB...")
        Chroma.from_documents(
            documents=final_chunks,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory=persist_directory
        )
        
        # Step 4: LÆ°u chunks vÃ o pickle (cho BM25)
        chunks_file = os.path.join(persist_directory, f"{collection_name}_chunks.pkl")
        with open(chunks_file, 'wb') as f:
            pickle.dump(final_chunks, f)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u chunks vÃ o {chunks_file}")
        
        print(f"\nâœ… HOÃ€N Táº¤T!")
        print(f"ğŸ“Š {len(section_docs)} sections â†’ {len(final_chunks)} chunks")
        print(f"ğŸ’¾ LÆ°u táº¡i: {persist_directory}")
    
    def query_with_hybrid_search(self, query, collection_name="knowledge_base", 
                                  persist_directory="data/chroma_db", k=5,
                                  bm25_weight=0.5, semantic_weight=0.5):
        
        print(f"\nğŸ” HYBRID SEARCH QUERY")
        print(f"="*70)
        print(f"â“ Query: {query}")
        print(f"ğŸ¯ Top K: {k}")
        print(f"âš–ï¸ Weights: BM25={bm25_weight}, Semantic={semantic_weight}")
        
        # Load vectorstore
        print(f"\nğŸ“‚ Äang load vectorstore...")
        vectorstore = Chroma(
            collection_name=collection_name,
            persist_directory=persist_directory,
            embedding_function=self.embeddings
        )
        
        # Load chunks cho BM25
        chunks_file = os.path.join(persist_directory, f"{collection_name}_chunks.pkl")
        with open(chunks_file, 'rb') as f:
            chunks = pickle.load(f)
        print(f"ğŸ“‚ ÄÃ£ load {len(chunks)} chunks")
        
        # Táº¡o BM25 retriever
        print(f"ğŸ”¤ Khá»Ÿi táº¡o BM25 retriever...")
        bm25_retriever = BM25Retriever.from_documents(chunks)
        bm25_retriever.k = k
        
        # Táº¡o Semantic retriever
        print(f"ğŸ§  Khá»Ÿi táº¡o Semantic retriever...")
        semantic_retriever = vectorstore.as_retriever(search_kwargs={"k": k})
        
        # Ensemble retriever
        print(f"ğŸ”€ Táº¡o Ensemble retriever...")
        hybrid_retriever = EnsembleRetriever(
            retrievers=[bm25_retriever, semantic_retriever],
            weights=[bm25_weight, semantic_weight]
        )
        
        # Query
        print(f"\nğŸ” Äang search...")
        results = hybrid_retriever.invoke(query)
        
        print(f"âœ… TÃ¬m tháº¥y {len(results)} káº¿t quáº£!")
        
        return results[:k]

